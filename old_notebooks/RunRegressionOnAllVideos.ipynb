{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import re\n",
    "import os, os.path\n",
    "from os.path import splitext\n",
    "import pydicom as dicom\n",
    "import numpy as np\n",
    "from pydicom.uid import UID, generate_uid\n",
    "import shutil\n",
    "from multiprocessing import dummy as multiprocessing\n",
    "import time\n",
    "import subprocess\n",
    "import datetime\n",
    "from datetime import date\n",
    "import sys\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "from shutil import copy\n",
    "import math\n",
    "import torch\n",
    "import torchvision\n",
    "import echonet\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 16/16 [00:12<00:00,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[32.36437  32.46042  33.180195] [49.859623 49.81081  50.567196]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "ds = echonet.datasets.Echo(root = \"C:\\\\Datasets\\\\ReleasedData\", split = \"all\")\n",
    "mean, std = echonet.utils.get_mean_and_std(ds)\n",
    "print(mean, std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda is available, original weights\n"
     ]
    }
   ],
   "source": [
    "# From https://github.com/echonet/dynamic/blob/master/scripts/InitializationNotebook.ipynb\n",
    "data = \"C:\\\\Datasets\\\\All A4c Videos from Database Query\\\\DownsampledAVIs\"\n",
    "regression_model_checkpoint = \"C:\\\\Users\\\\Remote\\\\Documents\\\\John\\\\dynamic\\\\Weights-20201103T193519Z-001\\\\Weights\\\\r2plus1d_18_32_2_pretrained.pt\"\n",
    "\n",
    "# Initialize and Run EF model\n",
    "\n",
    "frames = 32\n",
    "period = 2\n",
    "batch_size = 20\n",
    "model = torchvision.models.video.r2plus1d_18(pretrained=False)\n",
    "model.fc = torch.nn.Linear(model.fc.in_features, 1)\n",
    "\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(\"cuda is available, original weights\")\n",
    "    device = torch.device(\"cuda\")\n",
    "    model = torch.nn.DataParallel(model)\n",
    "    model.to(device)\n",
    "    checkpoint = torch.load(regression_model_checkpoint)\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "removed duplicates, 81757\n"
     ]
    }
   ],
   "source": [
    "unique_firstrun =  \"C:\\\\Datasets\\\\All A4c Videos from Database Query\\\\alreadyProcessedFiles-new2.csv\"\n",
    "\n",
    "kwargs = {\"target_type\": \"Filename\",\n",
    "          \"mean\": mean,\n",
    "          \"std\": std,\n",
    "          \"length\": frames,\n",
    "          \"period\": period\n",
    "          }\n",
    "\n",
    "test_ds = echonet.datasets.Echo(split = \"external_test\", external_test_location = data, **kwargs, clips=\"all\", duplicates_file = unique_firstrun) # unique_fnames) #\n",
    "#print(test_ds.split, test_ds.fnames)\n",
    "\n",
    "#ds = echonet.datasets.Echo(root = \"C:\\\\Datasets\\\\ReleasedData\", **kwargs, split = \"all\", clips = \"all\")\n",
    "\n",
    "test_dataloader = torch.utils.data.DataLoader(test_ds, batch_size = 1, num_workers = 5, shuffle = False, pin_memory=(device.type == \"cuda\"))\n",
    "# loss, yhat, y = echonet.utils.video.run_epoch(model, test_dataloader, train = False, optim = None, device = device, save_all=True, block_size = 20)\n",
    "\n",
    "# with tqdm.tqdm(total = len(test_dataloader)) as pbar:\n",
    "#     for X, outcome in test_dataloader:\n",
    "#         print(X.shape, outcome)\n",
    "\n",
    "# with open(output, \"w\") as g:\n",
    "#     for (filename, pred) in zip(ds.fnames, yhat):\n",
    "#         for (i,p) in enumerate(pred):\n",
    "#             g.write(\"{},{},{:.4f}\\n\".format(filename, i, p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████| 26693/26693 [12:39:28<00:00,  1.71s/it, 2902621.00 (26692.00)]\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "\n",
    "save_all = True\n",
    "block_size = 30\n",
    "train = False\n",
    "n = 0      # number of videos processed\n",
    "\n",
    "errorLog = os.path.join(\"C:\\\\Datasets\\\\All A4c Videos from Database Query\", \"allA4c_ef_output_ERROR_FILES.csv\")\n",
    "regression_output = os.path.join(\"C:\\\\Datasets\\\\All A4c Videos from Database Query\", \"allA4c_ef_output.csv\")\n",
    "\n",
    "with open(errorLog, 'w') as errors:\n",
    "    with open(regression_output, 'w') as g:\n",
    "        with torch.set_grad_enabled(train):\n",
    "            with tqdm.tqdm(total=len(test_dataloader)) as pbar:\n",
    "                for i, (X, outcome) in enumerate(test_dataloader):\n",
    "                    try:\n",
    "                        #print(X.shape, flush = True)\n",
    "\n",
    "                        #y.append(outcome.numpy())\n",
    "                        #X = X.to(device)\n",
    "                        #outcome = outcome.to(device)\n",
    "\n",
    "                        average = (len(X.shape) == 6)\n",
    "                        if average:\n",
    "                            batch, n_clips, c, f, h, w = X.shape\n",
    "                            X = X.view(-1, c, f, h, w)\n",
    "\n",
    "                        if block_size is None:\n",
    "                            outputs = model(X)\n",
    "                        else:\n",
    "\n",
    "                            for j in range(0, X.shape[0], block_size):\n",
    "                                thisX = X[j:(j + block_size)].to(device)\n",
    "                                thisOutput = model(thisX).detach().cpu()\n",
    "\n",
    "                                for k, l in enumerate(thisOutput):\n",
    "                                    #print(outcome[0], (j + k), l)\n",
    "                                    g.write(outcome[0] + \",\" + str(j + k) + \",\" + str(l.item()) + \"\\n\")\n",
    "\n",
    "                        n += X.size(0)\n",
    "\n",
    "                        pbar.set_postfix_str(\"{:.2f} ({:.2f})\".format( n, i))\n",
    "                        pbar.update()\n",
    "\n",
    "                        #print(s1, s2, total)\n",
    "                    except:\n",
    "                        print(X.shape, flush = True)\n",
    "                        print(\"something did not go right with\", outcome)\n",
    "                        errors.write(outcome[0] + \"\\n\")\n",
    "\n",
    "                    torch.cuda.empty_cache()\n",
    "                    #    print(\"cache cleared!\", torch.cuda.memory_allocated(0))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load already processed, to ignore in dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "previous files loaded\n",
      "81757\n"
     ]
    }
   ],
   "source": [
    "#Make a file with name of all files already run\n",
    "\n",
    "firstrun = \"C:\\\\Datasets\\\\All A4c Videos from Database Query\\\\allA4c_ef_output_thirdrun.csv\"\n",
    "unique_firstrun =  \"C:\\\\Datasets\\\\All A4c Videos from Database Query\\\\alreadyProcessedFiles-new2.csv\"\n",
    "unique_firstrun_previous =  \"C:\\\\Datasets\\\\All A4c Videos from Database Query\\\\alreadyProcessedFiles-new.csv\"\n",
    "\n",
    "unique_fnames = []\n",
    "\n",
    "with open(unique_firstrun_previous) as previous:\n",
    "    with open(firstrun, 'r') as f:\n",
    "        with open(unique_firstrun, 'w') as fout:\n",
    "            for line in previous.readlines():\n",
    "                fout.write(line)\n",
    "                unique_fnames.append(line.strip())\n",
    "            \n",
    "            print(\"previous files loaded\")#, unique_fnames)\n",
    "            \n",
    "            for line in f.readlines():\n",
    "                fname = line.split(',')[0]\n",
    "                if fname not in unique_fnames:\n",
    "                    unique_fnames.append(fname)\n",
    "                    fout.write(fname + \"\\n\")\n",
    "\n",
    "print(len(unique_fnames))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Previous runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▎                                                      | 649/108450 [19:12<49:13:51,  1.64s/it, 70238.00 (648.00)]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([123, 3, 32, 112, 112])\n",
      "something did not go right with ['1BTBOVQH.avi']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██████████▉                                   | 25664/108450 [12:07:21<25:23:35,  1.10s/it, 2757264.00 (25664.00)]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([147, 3, 32, 112, 112])\n",
      "something did not go right with ['3VPX4K99.avi']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██████████▉                                   | 25664/108450 [12:07:24<39:06:26,  1.70s/it, 2757264.00 (25664.00)]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: out of memory",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-23051e5364af>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     47\u001b[0m                         \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutcome\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"\\n\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 49\u001b[1;33m                     \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mempty_cache\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     50\u001b[0m                     \u001b[1;31m#    print(\"cache cleared!\", torch.cuda.memory_allocated(0))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\cuda\\memory.py\u001b[0m in \u001b[0;36mempty_cache\u001b[1;34m()\u001b[0m\n\u001b[0;32m     85\u001b[0m     \"\"\"\n\u001b[0;32m     86\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mis_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 87\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cuda_emptyCache\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     88\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA error: out of memory"
     ]
    }
   ],
   "source": [
    "save_all = True\n",
    "block_size = 20\n",
    "train = False\n",
    "n = 0      # number of videos processed\n",
    "\n",
    "errorLog = os.path.join(\"C:\\\\Datasets\\\\All A4c Videos from Database Query\", \"allA4c_ef_output_ERROR_FILES.csv\")\n",
    "regression_output = os.path.join(\"C:\\\\Datasets\\\\All A4c Videos from Database Query\", \"allA4c_ef_output.csv\")\n",
    "\n",
    "with open(errorLog, 'w') as errors:\n",
    "    with open(regression_output, 'w') as g:\n",
    "        with torch.set_grad_enabled(train):\n",
    "            with tqdm.tqdm(total=len(test_dataloader)) as pbar:\n",
    "                for i, (X, outcome) in enumerate(test_dataloader):\n",
    "                    try:\n",
    "                        #print(X.shape, flush = True)\n",
    "\n",
    "                        #y.append(outcome.numpy())\n",
    "                        #X = X.to(device)\n",
    "                        #outcome = outcome.to(device)\n",
    "\n",
    "                        average = (len(X.shape) == 6)\n",
    "                        if average:\n",
    "                            batch, n_clips, c, f, h, w = X.shape\n",
    "                            X = X.view(-1, c, f, h, w)\n",
    "\n",
    "                        if block_size is None:\n",
    "                            outputs = model(X)\n",
    "                        else:\n",
    "\n",
    "                            for j in range(0, X.shape[0], block_size):\n",
    "                                thisX = X[j:(j + block_size)].to(device)\n",
    "                                thisOutput = model(thisX).detach().cpu()\n",
    "\n",
    "                                for k, l in enumerate(thisOutput):\n",
    "                                    #print(outcome[0], (j + k), l)\n",
    "                                    g.write(outcome[0] + \",\" + str(j + k) + \",\" + str(l.item()) + \"\\n\")\n",
    "\n",
    "                        n += X.size(0)\n",
    "\n",
    "                        pbar.set_postfix_str(\"{:.2f} ({:.2f})\".format( n, i))\n",
    "                        pbar.update()\n",
    "\n",
    "                        #print(s1, s2, total)\n",
    "                    except:\n",
    "                        print(X.shape, flush = True)\n",
    "                        print(\"something did not go right with\", outcome)\n",
    "                        errors.write(outcome[0] + \"\\n\")\n",
    "\n",
    "                    torch.cuda.empty_cache()\n",
    "                    #    print(\"cache cleared!\", torch.cuda.memory_allocated(0))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|███████████████████▍                            | 18243/44937 [8:52:01<18:13:58,  2.46s/it, 2021596.00 (18242.00)]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([240, 3, 32, 112, 112])\n",
      "something did not go right with ['BSILDU76.avi']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|███████████████████▍                            | 18243/44937 [8:52:05<12:58:34,  1.75s/it, 2021596.00 (18242.00)]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: out of memory",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-1a733b1fc83d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     49\u001b[0m                         \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutcome\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"\\n\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m                     \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mempty_cache\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     52\u001b[0m                     \u001b[1;31m#    print(\"cache cleared!\", torch.cuda.memory_allocated(0))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\cuda\\memory.py\u001b[0m in \u001b[0;36mempty_cache\u001b[1;34m()\u001b[0m\n\u001b[0;32m     85\u001b[0m     \"\"\"\n\u001b[0;32m     86\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mis_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 87\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cuda_emptyCache\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     88\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA error: out of memory"
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "\n",
    "save_all = True\n",
    "block_size = 30\n",
    "train = False\n",
    "n = 0      # number of videos processed\n",
    "\n",
    "errorLog = os.path.join(\"C:\\\\Datasets\\\\All A4c Videos from Database Query\", \"allA4c_ef_output_ERROR_FILES.csv\")\n",
    "regression_output = os.path.join(\"C:\\\\Datasets\\\\All A4c Videos from Database Query\", \"allA4c_ef_output.csv\")\n",
    "\n",
    "with open(errorLog, 'w') as errors:\n",
    "    with open(regression_output, 'w') as g:\n",
    "        with torch.set_grad_enabled(train):\n",
    "            with tqdm.tqdm(total=len(test_dataloader)) as pbar:\n",
    "                for i, (X, outcome) in enumerate(test_dataloader):\n",
    "                    try:\n",
    "                        #print(X.shape, flush = True)\n",
    "\n",
    "                        #y.append(outcome.numpy())\n",
    "                        #X = X.to(device)\n",
    "                        #outcome = outcome.to(device)\n",
    "\n",
    "                        average = (len(X.shape) == 6)\n",
    "                        if average:\n",
    "                            batch, n_clips, c, f, h, w = X.shape\n",
    "                            X = X.view(-1, c, f, h, w)\n",
    "\n",
    "                        if block_size is None:\n",
    "                            outputs = model(X)\n",
    "                        else:\n",
    "\n",
    "                            for j in range(0, X.shape[0], block_size):\n",
    "                                thisX = X[j:(j + block_size)].to(device)\n",
    "                                thisOutput = model(thisX).detach().cpu()\n",
    "\n",
    "                                for k, l in enumerate(thisOutput):\n",
    "                                    #print(outcome[0], (j + k), l)\n",
    "                                    g.write(outcome[0] + \",\" + str(j + k) + \",\" + str(l.item()) + \"\\n\")\n",
    "\n",
    "                        n += X.size(0)\n",
    "\n",
    "                        pbar.set_postfix_str(\"{:.2f} ({:.2f})\".format( n, i))\n",
    "                        pbar.update()\n",
    "\n",
    "                        #print(s1, s2, total)\n",
    "                    except:\n",
    "                        print(X.shape, flush = True)\n",
    "                        print(\"something did not go right with\", outcome)\n",
    "                        errors.write(outcome[0] + \"\\n\")\n",
    "\n",
    "                    torch.cuda.empty_cache()\n",
    "                    #    print(\"cache cleared!\", torch.cuda.memory_allocated(0))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
